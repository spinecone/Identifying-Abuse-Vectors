# Exercise 2: Automated abuse prevention

The options we discussed for addressing abuse vectors can be divided into two categories: tools that **automatically** prevent or penalize harassment, and tools that **empower humans** to do so. For this exercise, we're just going to focus on the **automatic tools**, making anti-harassment robots to do our work for us:

* **Take out the feature**

* **Reduce interaction**

* **Reduce visibility**

* **Don't keep data you don't need**

Going back to the abuse vectors you identified in the last exercise, try to think of solutions to them using these principles. The components of a solution to an abuse vector looks pretty much like any software feature proposal. You'll want to make sure you've thought about:

* **How does this address the abuse vector?** Is there** **any way around it if someone is persistent or clever enough?

* **What are the changes to the UI? **Is this going to be a drastic change? Will users need help navigating the new design?

* **What are the tradeoffs being made? **Is this change going to make the product less fun? More confusing?

* **How does this affect the business? ** Could this affect** **revenue or public perception of the company?

* **What alternatives are there? **There should be at least one other option so that decision makers can weigh pros and cons



