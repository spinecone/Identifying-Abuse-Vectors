# Exercise 3: Empowering humans to prevent abuse

There's a misconception that the ideal form of online abuse prevention would look like an all-seeing, all-powerful robot that either knows how to keep abuse from ever happening, or immediately punishes anyone who commits abuse. In reality, some of the most important work of preventing and punishing abuse is done by people.

Moderators are an extremely important part of every online community. They know what typical conflicts look like, the strategies that tend to be successful in resolving them, and the strategies that aren't. They're also usually more effective than a robot would be at helping someone realize they're being a jerk and that they can do better.

People can also be empowered to keep themselves from harassing others. This can look like encouragement not to engage in harassing behavior \("You just messaged this person 5 times in a row with no response, are you sure you want to keep doing that?"\), or an appropriate punishment afterward \("You messaged this person 10 times within 60 seconds so we're going to prevent you from posting for the next few minutes"\).

For our last exercise, we'll design abuse prevention tools that empower to humans to stop themselves and each other from harassing others. To review, those tools are:

* **Intervene before, during, and after harassment**

* **Make it opt-in**

* **Add moderation**

These tools are useful for when it's just not possible or practical to alter features from their present state, even if they're abuse vectors.

Take about 20 minutes to design tools for moderating, discouraging bad behavior before it occurs, and punishing users who have harassed so they'll be less likely to do it again.

